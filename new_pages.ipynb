{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1337c682",
   "metadata": {},
   "source": [
    "# Czech Wikipedia in the covid era: New pages\n",
    "\n",
    "This notebook shows data about pages created at Czech Wikipedia during years 2020 and 2019.\n",
    "\n",
    "Created by Martin Urbanec, Wikimedia Czech Republic. WIP notebook, do not rely on (yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272680d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wmfdata import spark\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab02c23b",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c47d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNAPSHOT = '2021-05'\n",
    "PROJECT='cs.wikipedia'\n",
    "DBNAME = 'cswiki'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce30cd22",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19430adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataframes(file_2019, file_2020, suffixes=('_2019', '_2020')):\n",
    "    df_2019 = pd.read_csv(file_2019, sep='\\t')\n",
    "    df_2019['date'] = df_2019.date.str.replace('2019-', 'year-')\n",
    "    df_2019.set_index('date', inplace=True)\n",
    "\n",
    "    df_2020 = pd.read_csv(file_2020, sep='\\t')\n",
    "    df_2020['date'] = df_2020.date.str.replace('2020-', 'year-')\n",
    "    df_2020.set_index('date', inplace=True)\n",
    "\n",
    "    df = df_2019.merge(df_2020, left_index=True, right_index=True, suffixes=suffixes)\n",
    "    df.reset_index(inplace=True)\n",
    "    df['date'] = df.date.str.replace('year-', '2020-')\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce476575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_multiple_dataframes(dfs, main_year='2020', values='new_pages'):\n",
    "    formattedDfs = []\n",
    "    for df in dfs:\n",
    "        year = df.date[0].split('-')[0]\n",
    "        df['year'] = [year] * len(df.index)\n",
    "        df['date'] = df.date.str.replace('%s-' % year, '%s-' % main_year)\n",
    "        formattedDfs.append(df)\n",
    "    \n",
    "    res = pd.concat(formattedDfs)\n",
    "    return res.pivot_table(index='date', columns=['year'], values=values, fill_value=0, aggfunc=sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba640e",
   "metadata": {},
   "source": [
    "## New survived pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6854a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_pages_daily(start_ts, end_ts):\n",
    "    df = spark.run('''\n",
    "    SELECT\n",
    "        TO_DATE(ts) AS `date`,\n",
    "        SUM(edit_count) AS new_pages\n",
    "    FROM wmf.edit_hourly\n",
    "    WHERE\n",
    "            snapshot=\"{snapshot}\"\n",
    "        AND project=\"{project}\"\n",
    "\n",
    "        -- we're interested in data from given timeframe\n",
    "        AND ts >= '{start_ts}'\n",
    "        AND ts <= '{end_ts}'\n",
    "\n",
    "        -- exclude known bots\n",
    "        AND user_is_bot=false\n",
    "\n",
    "        -- filter for content edits only\n",
    "        AND namespace_is_content=true\n",
    "        \n",
    "        -- and only for new pages...\n",
    "        AND creates_new_page=true\n",
    "        \n",
    "        -- and only for survived pages\n",
    "        AND is_deleted=false\n",
    "    \n",
    "    GROUP BY\n",
    "        `date`\n",
    "    ORDER BY `date`\n",
    "    '''.format(\n",
    "        snapshot=SNAPSHOT,\n",
    "        project=PROJECT,\n",
    "        start_ts=start_ts,\n",
    "        end_ts=end_ts\n",
    "    ))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea7b0d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>new_pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  new_pages\n",
       "0  2020-01-02        124\n",
       "1  2020-01-03         96\n",
       "2  2020-01-04        150\n",
       "3  2020-01-05        157\n",
       "4  2020-01-06        125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_new_pages_daily('2020-01-01T00:00:00', '2020-12-31T23:59:59')\n",
    "df.to_csv('data/new_survived_articles_daily_2020.tsv', sep='\\t', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71b6d33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>new_pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  new_pages\n",
       "0  2019-01-02        121\n",
       "1  2019-01-03         82\n",
       "2  2019-01-04        119\n",
       "3  2019-01-05         96\n",
       "4  2019-01-06         84"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_new_pages_daily('2019-01-01T00:00:00', '2019-12-31T23:59:59')\n",
    "df.to_csv('data/new_survived_articles_daily_2019.tsv', sep='\\t', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62abce2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>new_pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  new_pages\n",
       "0  2018-01-02        132\n",
       "1  2018-01-03        181\n",
       "2  2018-01-04        105\n",
       "3  2018-01-05        191\n",
       "4  2018-01-06        252"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_new_pages_daily('2018-01-01T00:00:00', '2018-12-31T23:59:59')\n",
    "df.to_csv('data/new_survived_articles_daily_2018.tsv', sep='\\t', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2f9356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>new_pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  new_pages\n",
       "0  2017-01-02        150\n",
       "1  2017-01-03        138\n",
       "2  2017-01-04        129\n",
       "3  2017-01-05        165\n",
       "4  2017-01-06        126"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_new_pages_daily('2017-01-01T00:00:00', '2017-12-31T23:59:59')\n",
    "df.to_csv('data/new_survived_articles_daily_2017.tsv', sep='\\t', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "030a7e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>150</td>\n",
       "      <td>132</td>\n",
       "      <td>121</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>138</td>\n",
       "      <td>181</td>\n",
       "      <td>82</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>129</td>\n",
       "      <td>105</td>\n",
       "      <td>119</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>165</td>\n",
       "      <td>191</td>\n",
       "      <td>96</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>126</td>\n",
       "      <td>252</td>\n",
       "      <td>84</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year        2017  2018  2019  2020\n",
       "date                              \n",
       "2020-01-02   150   132   121   124\n",
       "2020-01-03   138   181    82    96\n",
       "2020-01-04   129   105   119   150\n",
       "2020-01-05   165   191    96   157\n",
       "2020-01-06   126   252    84   125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = merge_multiple_dataframes([pd.read_csv(x, sep='\\t') for x in [\n",
    "    'data/new_survived_articles_daily_2017.tsv',\n",
    "    'data/new_survived_articles_daily_2018.tsv',\n",
    "    'data/new_survived_articles_daily_2019.tsv',\n",
    "    'data/new_survived_articles_daily_2020.tsv'\n",
    "]], values='new_pages')\n",
    "df.to_csv('data/new_survived_articles_daily_2016_2020.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4c80e2",
   "metadata": {},
   "source": [
    "## Unique page creators\n",
    "\n",
    "Non-redirect pages created by human users that survived (were not deleted by an admin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec60afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_page_creators(start_ts, end_ts):\n",
    "    return spark.run('''\n",
    "    SELECT\n",
    "        TO_DATE(event_timestamp) AS `date`,\n",
    "        COUNT(DISTINCT coalesce(event_user_id, event_user_text)) AS unique_page_creators\n",
    "    FROM wmf.mediawiki_history\n",
    "    WHERE\n",
    "            snapshot='{snapshot}'\n",
    "\n",
    "        -- we're interested in dbname's event\n",
    "        AND wiki_db='{dbname}'\n",
    "\n",
    "        -- we're interested in new pages created by human users, excluding redirects\n",
    "        AND event_entity='page'\n",
    "        AND event_type='create'\n",
    "        AND user_is_bot_by_historical IS NULL\n",
    "        AND page_is_redirect=false\n",
    "\n",
    "        -- in given date\n",
    "        AND event_timestamp >= '{start_ts}'\n",
    "        AND event_timestamp <= '{end_ts}'\n",
    "\n",
    "        -- and only pages that survived\n",
    "        AND page_is_deleted=false\n",
    "\n",
    "    GROUP BY `date`\n",
    "    ORDER BY `date`\n",
    "    '''.format(\n",
    "        snapshot=SNAPSHOT,\n",
    "        dbname=DBNAME,\n",
    "        start_ts=start_ts,\n",
    "        end_ts=end_ts\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_unique_page_creators('2020-01-01T00:00:00', '2020-12-31T23:59:59')\n",
    "df.to_csv('data/unique_page_creators_2020.tsv', sep='\\t', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_unique_page_creators('2019-01-01T00:00:00', '2019-12-31T23:59:59')\n",
    "df.to_csv('data/unique_page_creators_2019.tsv', sep='\\t', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merge_dataframes('data/unique_page_creators_2019.tsv', 'data/unique_page_creators_2020.tsv')\n",
    "df.to_csv('data/unique_page_creators_2019_2020.tsv', sep='\\t')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
